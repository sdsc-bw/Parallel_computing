{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABEL_PATH = \"data/train_labels.csv\"\n",
    "TRAIN_PATH = \"data/train/\"\n",
    "\n",
    "# label dataframe \n",
    "label = pd.read_csv(TRAIN_LABEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "feture_to_extract = {\"mean\":np.mean,\n",
    "                    \"max\":np.max,\n",
    "                    \"min\":np.min,\n",
    "                    \"var\":np.var}\n",
    "\n",
    "def get_feature(args):\n",
    "    _file_path = args\n",
    "    _df = pd.read_csv(_file_path)\n",
    "    _file_name = _file_path.split('/')[-1]\n",
    "    _feature_values = []\n",
    "    \n",
    "    # Extracting the mean from the time series as a feature\n",
    "    for key in feture_to_extract.keys():\n",
    "        _feature_values.extend(list(feture_to_extract[key](_df).values))\n",
    "\n",
    " \n",
    "    return _feature_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [20:00<00:00, 39.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract features from train (time series)\n",
    "dict_result = {}\n",
    "for folds in tqdm(os.listdir(TRAIN_PATH)):\n",
    "    dict_temp = {}\n",
    "    nargs = os.listdir(TRAIN_PATH + folds)\n",
    "    nargs = [(TRAIN_PATH + folds + '/' + _i) for _i in nargs]\n",
    "    for item in nargs:\n",
    "        dict_temp[item.split(\"/\")[-1]] = get_feature(item)\n",
    "    dict_result.update(dict_temp)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_csv(item)\n",
    "columns =  _df.columns\n",
    "feature_columns = []\n",
    "for key in feture_to_extract.keys():\n",
    "    for column in columns:\n",
    "        feature_columns.append(key+\"_\"+column)\n",
    "        \n",
    "feature_columns.append(\"ret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict_result)\n",
    "# train.head()\n",
    "train = train.T\n",
    "train['file_name'] = train.index\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "train = pd.merge(train, label[['file_name', 'ret']], on='file_name', how='left')\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "del train[\"file_name\"]\n",
    "\n",
    "train.columns = feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: parallel along folds\n",
    "def extract_features_from_files_in_folds(folds):\n",
    "    dict_result = {}\n",
    "    dict_temp = {}\n",
    "    nargs = os.listdir(TRAIN_PATH + folds)\n",
    "    nargs = [(TRAIN_PATH + folds + '/' + _i) for _i in nargs]\n",
    "    for item in nargs:\n",
    "        dict_temp[item.split(\"/\")[-1]] = get_feature(item)\n",
    "    dict_result.update(dict_temp)\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2: parallel along files\n",
    "files = []\n",
    "for folds in os.listdir(TRAIN_PATH):\n",
    "    nargs = os.listdir(TRAIN_PATH + folds)\n",
    "    nargs = [(TRAIN_PATH + folds + '/' + _i) for _i in nargs]\n",
    "    files.extend(nargs)\n",
    "def extract_features_from_file(file):\n",
    "    dict_temp = {}\n",
    "    dict_temp[file.split(\"/\")[-1]] = get_feature(file)\n",
    "    return dict_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method1: parallel along folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      " 32%|███▏      | 8/25 [00:00<00:00, 30.44it/s]\u001b[A\n",
      " 64%|██████▍   | 16/25 [00:02<00:00,  9.48it/s]\u001b[A\n",
      " 96%|█████████▌| 24/25 [01:17<00:02,  2.88s/it]\u001b[A\n",
      "100%|██████████| 25/25 [01:17<00:00,  3.09s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "234.10961723327637"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1: parallel along folds\n",
    "time_start = time.time()\n",
    "results = Parallel(n_jobs=8)(delayed(extract_features_from_files_in_folds)(i) for i in tqdm(os.listdir(TRAIN_PATH)))\n",
    "time_finish = time.time()\n",
    "print('The total time taken for Parallel Method 1 is %d'%(time_finish - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method 2: parallel along files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49647/49647 [02:38<00:00, 314.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time taken for Parallel Method 2 is: 158\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "results = Parallel(n_jobs=8)(delayed(extract_features_from_file)(i) for i in tqdm(files))\n",
    "time_finish = time.time()\n",
    "print('The total time taken for Parallel Method 2 is: %d'%(time_finish - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "import dask\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39534</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>25</li>\n",
       "  <li><b>Cores: </b>50</li>\n",
       "  <li><b>Memory: </b>269.89 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:39534' processes=25 cores=50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers = 25)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: parallel along folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "tmp = client.map(extract_features_from_files_in_folds, os.listdir(TRAIN_PATH))\n",
    "def combine(results):\n",
    "    dic = {}\n",
    "    for i in results:\n",
    "        dic.update(i)\n",
    "output = client.submit(combine, tmp)\n",
    "#result = output.result()\n",
    "time_finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time taken for Parallel Method 1 is: 165\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "result = output.result()\n",
    "time_finish = time.time()\n",
    "print('The total time taken for Parallel Method 1 is: %d'%(time_finish - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: parallel along files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "tmp = client.map(extract_features_from_file, files)\n",
    "def combine(results):\n",
    "    dic = {}\n",
    "    for i in results:\n",
    "        dic.update(i)\n",
    "output = client.submit(combine, tmp)\n",
    "result = output.result()\n",
    "time_finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time taken for Parallel Method 2 is: 135\n"
     ]
    }
   ],
   "source": [
    "print('The total time taken for Parallel Method 2 is: %d'%(time_finish - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intake + Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.iloc[:,:-1].get_values()\n",
    "y = train.iloc[:,-1].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of training is  0.9998422264996372\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_train_prediction = classifier.predict(X_train)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_train, y_train_prediction)\n",
    "print(\"The f1 score of training is \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of test is  0.970970206264324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_test_prediction = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_test_prediction)\n",
    "print(\"The f1 score of test is \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_mining]",
   "language": "python",
   "name": "conda-env-data_mining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
